Metadata-Version: 2.4
Name: GraphUniverse
Version: 0.0.1
Summary: Graph Universe: A Library for Generating Inductive Graph Datasets
Author-email: Louis Van Langendonck <louis.van.langendonck@upc.edu>
Project-URL: repository, https://github.com/LouisVanLangendonck/GraphUniverse
Classifier: License :: OSI Approved :: MIT License
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Science/Research
Classifier: Topic :: Scientific/Engineering
Classifier: Topic :: Scientific/Engineering :: Mathematics
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Natural Language :: English
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Python: >=3.10
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: scikit-optimize
Requires-Dist: torch
Requires-Dist: torch-geometric
Requires-Dist: scipy
Requires-Dist: torchdiffeq
Requires-Dist: matplotlib
Requires-Dist: tqdm
Requires-Dist: streamlit
Requires-Dist: omegaconf
Requires-Dist: seaborn
Requires-Dist: wandb
Requires-Dist: tensorboard
Requires-Dist: einops==0.7.0
Requires-Dist: tabulate
Requires-Dist: ipykernel
Requires-Dist: notebook
Requires-Dist: jupyterlab
Requires-Dist: rich
Requires-Dist: rootutils
Requires-Dist: scikit-optimize
Provides-Extra: doc
Requires-Dist: jupyter; extra == "doc"
Requires-Dist: nbsphinx; extra == "doc"
Requires-Dist: nbsphinx_link; extra == "doc"
Requires-Dist: numpydoc; extra == "doc"
Requires-Dist: sphinx; extra == "doc"
Requires-Dist: sphinx_gallery; extra == "doc"
Requires-Dist: pydata-sphinx-theme; extra == "doc"
Requires-Dist: myst_parser; extra == "doc"
Provides-Extra: lint
Requires-Dist: pre-commit; extra == "lint"
Requires-Dist: ruff>=0.1.0; extra == "lint"
Provides-Extra: test
Requires-Dist: pytest>=7.0; extra == "test"
Requires-Dist: pytest-cov; extra == "test"
Requires-Dist: coverage; extra == "test"
Requires-Dist: jupyter; extra == "test"
Requires-Dist: mypy; extra == "test"
Requires-Dist: pytest-mock; extra == "test"
Provides-Extra: dev
Requires-Dist: GraphUniverse[lint,test]; extra == "dev"
Provides-Extra: all
Requires-Dist: GraphUniverse[dev,doc]; extra == "all"
Dynamic: license-file

# Graph Universe

This repo is proposing proposing:

- A **core generative universe**: a large, structured SBM (with overlapping communities and complex edge patterns)
- A **distribution over graph instances**: each sampled from different *subsets* of this universe
- A training setup where self-supervised methods pretrain across this rich distribution
- A **transfer learning scenario**: test graphs with **new combinations or unseen subsets** + sparse supervision (labels)

### âœ… Why this is a powerful idea:
- You're simulating **distributional shifts** across tasks (like in natural language or vision benchmarks).
- You're using **shared latent structure** (the overlapping communities in a large SBM) to encourage models to generalize.
- This is analogous to **pretraining on a wide range of domains**, then adapting with few-shot learning.

---

## ðŸ”§ How to implement "sampling from the core SBM"

Letâ€™s now break down **how to go from a global SBM to a sampled graph**:

---

### **1. Define the core generative structure ("Graph Universe")**

You begin with:

- \( K \): total number of community types (say 100)
- \( P \in [0,1]^{K \times K} \): edge probability matrix
- Optional:
  - A **node type to feature prototype** mapping (for feature generation)
  - A **community co-membership matrix** (to simulate typical overlaps)

You now have the **full vocabulary** of behaviors.

---

### **2. Sample a graph instance from this universe**

Each graph is a **subset** of this universe:

#### **a. Select a subset of communities**
Choose a subset \( S \subset \{1, \ldots, K\} \), e.g. 10 out of 100.

You can control:
- Diversity (choose similar vs dissimilar communities)
- Difficulty (choose overlapping or ambiguous subsets)

#### **b. Define the size and node distribution**
- Sample how many nodes per community (e.g. power-law, uniform)
- Allow **overlap**: a node can belong to multiple selected communities
- Assign each node a (possibly mixed) community membership vector \( \pi_i \)

#### **c. Sample node features (optional)**
- If using prototypes: generate features \( x_i \sim \mathcal{N}(\mu_{\pi_i}, \Sigma) \)
- Or use more elaborate encoding per community

#### **d. Generate edges**
You now use a **degree-corrected MMSBM-like rule**:

For each node pair \( i, j \):
1. Sample community pair \( (a, b) \sim \pi_i \otimes \pi_j \)
2. Use degree-scaled probability:
   \[
   p_{ij} = \theta_i \theta_j P_{ab}
   \]
3. Sample \( A_{ij} \sim \text{Bernoulli}(p_{ij}) \)

This is **a generalization of DC-MMSBM**, and lets you:
- Preserve statistical edge structure
- Embed real overlap
- Control node degrees and community mixing

---

### **3. Repeat many times to generate a benchmark**

Each graph instance has:
- A specific subset of node types
- Community overlaps and induced structure
- Features generated conditionally on communities
- Structural patterns sampled from \( P \)

Over time, **shared structural patterns** emerge across graphs:
- Some community combinations appear often
- Some connection motifs become frequent
- The model can learn general **inter-community dynamics**

---

### **4. Use this for pretraining and transfer learning**

#### **Pretraining**
- Self-supervised tasks (e.g. contrastive learning, masked edges/nodes)
- No community labels needed
- Goal: learn representations that generalize across graphs

#### **Transfer Tasks**
- Sample new graphs with:
  - Unseen or rare community subsets
  - Sparse node labels (few labeled nodes)
- Task: predict community memberships, labels, or edge patterns
- This tests **few-shot generalization** based on learned structure

---

## ðŸ’¡ Bonus: Sampling tricks

To make this scalable and flexible:
- Use **sampling-by-membership** (only compute edge probabilities between nodes that share at least one community)
- Use **sparse graph construction** (skip low-probability edges)
- Precompute a "meta-graph" over communities (learn high-level structure too)
