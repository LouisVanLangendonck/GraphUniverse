{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e71ee12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"run_id\": int\n",
      "  \"timestamp\": str\n",
      "  \"sweep_parameters\":   {\n",
      "    \"universe_homophily\": float\n",
      "    \"universe_edge_density\": float\n",
      "    \"n_graphs\": int\n",
      "    \"homophily_range_max\": float\n",
      "    \"density_range_max\": float\n",
      "    \"allow_unseen_community_combinations_for_eval\": bool\n",
      "  }\n",
      "  \"random_parameters\":   {\n",
      "  }\n",
      "  \"all_parameters\":   {\n",
      "    \"universe_homophily\": float\n",
      "    \"universe_edge_density\": float\n",
      "    \"n_graphs\": int\n",
      "    \"homophily_range_max\": float\n",
      "    \"density_range_max\": float\n",
      "    \"allow_unseen_community_combinations_for_eval\": bool\n",
      "  }\n",
      "  \"method\": str\n",
      "  \"degree_distribution\": str\n",
      "  \"family_properties\":   {\n",
      "    \"n_graphs\": int\n",
      "    \"node_counts\":     [\n",
      "      ...\n",
      "      ... (200 items)\n",
      "    ]\n",
      "    \"edge_counts\":     [\n",
      "      ...\n",
      "      ... (200 items)\n",
      "    ]\n",
      "    \"densities\":     [\n",
      "      ...\n",
      "      ... (200 items)\n",
      "    ]\n",
      "    \"avg_degrees\":     [\n",
      "      ...\n",
      "      ... (200 items)\n",
      "    ]\n",
      "    \"clustering_coefficients\":     [\n",
      "      ...\n",
      "      ... (200 items)\n",
      "    ]\n",
      "    \"community_counts\":     [\n",
      "      ...\n",
      "      ... (200 items)\n",
      "    ]\n",
      "    \"homophily_levels\":     [\n",
      "      ...\n",
      "      ... (200 items)\n",
      "    ]\n",
      "    \"generation_methods\":     [\n",
      "      ...\n",
      "      ... (200 items)\n",
      "    ]\n",
      "    \"node_counts_mean\": float\n",
      "    \"node_counts_std\": float\n",
      "    \"node_counts_min\": float\n",
      "    \"node_counts_max\": float\n",
      "    \"edge_counts_mean\": float\n",
      "    \"edge_counts_std\": float\n",
      "    \"edge_counts_min\": float\n",
      "    \"edge_counts_max\": float\n",
      "    \"densities_mean\": float\n",
      "    \"densities_std\": float\n",
      "    \"densities_min\": float\n",
      "    \"densities_max\": float\n",
      "    \"avg_degrees_mean\": float\n",
      "    \"avg_degrees_std\": float\n",
      "    \"avg_degrees_min\": float\n",
      "    \"avg_degrees_max\": float\n",
      "    \"clustering_coefficients_mean\": float\n",
      "    \"clustering_coefficients_std\": float\n",
      "    \"clustering_coefficients_min\": float\n",
      "    \"clustering_coefficients_max\": float\n",
      "    \"community_counts_mean\": float\n",
      "    \"community_counts_std\": float\n",
      "    \"community_counts_min\": float\n",
      "    \"community_counts_max\": float\n",
      "    \"homophily_levels_mean\": float\n",
      "    \"homophily_levels_std\": float\n",
      "    \"homophily_levels_min\": float\n",
      "    \"homophily_levels_max\": float\n",
      "    \"generation_method_distribution\":     {\n",
      "      \"dccc_sbm\": int\n",
      "    }\n",
      "  }\n",
      "  \"family_consistency\":   {\n",
      "    \"pattern_preservation\":     {\n",
      "      \"score\": float\n",
      "      \"individual_correlations\":       ...\n",
      "      \"std\": float\n",
      "      \"interpretation\": str\n",
      "      \"description\": str\n",
      "    }\n",
      "    \"generation_fidelity\":     {\n",
      "      \"score\": float\n",
      "      \"individual_scores\":       ...\n",
      "      \"std\": float\n",
      "      \"interpretation\": str\n",
      "      \"description\": str\n",
      "    }\n",
      "    \"degree_consistency\":     {\n",
      "      \"score\": float\n",
      "      \"individual_scores\":       ...\n",
      "      \"std\": float\n",
      "      \"interpretation\": str\n",
      "      \"description\": str\n",
      "    }\n",
      "    \"triangle_consistency\":     {\n",
      "      \"score\": float\n",
      "      \"mean_correlation\": float\n",
      "      \"mean_triangle_density\": float\n",
      "      \"std\": float\n",
      "      \"interpretation\": str\n",
      "      \"description\": str\n",
      "    }\n",
      "    \"cooccurrence_consistency\":     {\n",
      "      \"score\": float\n",
      "      \"difference_matrix\":       ...\n",
      "      \"interpretation\": str\n",
      "      \"description\": str\n",
      "    }\n",
      "    \"overall\":     {\n",
      "      \"score\": float\n",
      "      \"interpretation\": str\n",
      "      \"description\": str\n",
      "    }\n",
      "    \"community_coverage\":     {\n",
      "      \"total_unique_communities\": int\n",
      "      \"universe_communities\": int\n",
      "      \"coverage_fraction\": float\n",
      "      \"community_usage\":       ...\n",
      "      \"avg_usage_per_community\": float\n",
      "      \"usage_std\": float\n",
      "      \"min_usage\": int\n",
      "      \"max_usage\": int\n",
      "      \"communities_in_all_graphs\":       ...\n",
      "      \"rarely_used_communities\":       ...\n",
      "    }\n",
      "  }\n",
      "  \"community_signals\":   {\n",
      "    \"degree_signals\":     {\n",
      "      \"mean\": float\n",
      "      \"std\": float\n",
      "      \"min\": float\n",
      "      \"max\": float\n",
      "      \"individual_values\":       ...\n",
      "    }\n",
      "    \"structure_signals\":     {\n",
      "      \"mean\": float\n",
      "      \"std\": float\n",
      "      \"min\": float\n",
      "      \"max\": float\n",
      "      \"individual_values\":       ...\n",
      "    }\n",
      "    \"feature_signals\":     {\n",
      "      \"mean\": float\n",
      "      \"std\": float\n",
      "      \"min\": float\n",
      "      \"max\": float\n",
      "      \"individual_values\":       ...\n",
      "    }\n",
      "  }\n",
      "  \"model_results\":   {\n",
      "    \"community\":     {\n",
      "      \"gcn_PE\":       ...\n",
      "      \"sage_PE\":       ...\n",
      "      \"gin_PE\":       ...\n",
      "      \"gat_PE\":       ...\n",
      "      \"graphgps\":       ...\n",
      "      \"sheaf_diffusion_PE\":       ...\n",
      "      \"mlp_PE\":       ...\n",
      "    }\n",
      "  }\n",
      "  \"total_time\": int\n",
      "  \"n_graphs\": int\n",
      "  \"universe_K\": int\n",
      "  \"tasks\":   [\n",
      "str\n",
      "  ]\n",
      "  \"data_files\":   {\n",
      "    \"inductive_data\": str\n",
      "    \"sheaf_inductive_data\": str\n",
      "    \"family_graphs\": str\n",
      "    \"config_path\": str\n",
      "  }\n",
      "  \"unseen_community_combination_score\": float\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "from typing import Dict, Any, List\n",
    "import numpy as np\n",
    "\n",
    "def get_result_family_properties(main_dir, multi_inductive_experiment_dir, run_sample):\n",
    "    run = run_sample['data_files']['inductive_data'].split(\"/\")[0]\n",
    "    # Get path of run\n",
    "    run_path = os.path.join(main_dir, multi_inductive_experiment_dir, run)\n",
    "    # find the non-empty DIRECTORY (not file) in the run_path\n",
    "    for dir in os.listdir(run_path):\n",
    "        if os.path.isdir(os.path.join(run_path, dir)) and dir != \"\" and dir != \"data_analysis_report.txt\":\n",
    "            # Load in results.json of that directory\n",
    "            results = json.load(open(os.path.join(run_path, dir, \"results.json\")))\n",
    "            # Get the result family properties\n",
    "            result_family_properties = results['family_properties']\n",
    "            return result_family_properties \n",
    "        \n",
    "def add_family_properties_to_run_sample(main_dir, multi_inductive_experiment_dir, run_sample):\n",
    "    family_properties = get_result_family_properties(main_dir, multi_inductive_experiment_dir, run_sample)\n",
    "    # Make big dataframe with each of the family properties that have _mean, _std, _min, _max in the name\n",
    "    run_sample['family_properties'] = family_properties\n",
    "\n",
    "    return run_sample\n",
    "\n",
    "# Get name of directoyy 2 levels up \n",
    "main_dir = os.path.dirname(os.getcwd())\n",
    "\n",
    "# Define the multi-inductive experiment directory\n",
    "multi_inductive_experiment_dir = \"multi_results/final_sweep_community\"\n",
    "\n",
    "# Load in the final_results.json \n",
    "data = json.load(open(os.path.join(main_dir, multi_inductive_experiment_dir, \"final_results.json\")))\n",
    "\n",
    "# Print the data\n",
    "run_sample = data['all_results'][0]\n",
    "run_sample = add_family_properties_to_run_sample(main_dir, multi_inductive_experiment_dir, run_sample)\n",
    "\n",
    "# Convert the data to a dataframe\n",
    "results_list_with_family_properties = []\n",
    "for run_sample in data['all_results']:\n",
    "    run_sample = add_family_properties_to_run_sample(main_dir, multi_inductive_experiment_dir, run_sample)\n",
    "    results_list_with_family_properties.append(run_sample)\n",
    "\n",
    "\n",
    "\n",
    "def print_json_skeleton(obj, indent=0, max_depth=3, current_depth=0):\n",
    "    \"\"\"\n",
    "    Print the skeleton structure of a JSON object, showing keys and data types\n",
    "    without printing the actual values (except for simple types).\n",
    "    \"\"\"\n",
    "    if current_depth >= max_depth:\n",
    "        print(\"  \" * indent + \"...\")\n",
    "        return\n",
    "    \n",
    "    if isinstance(obj, dict):\n",
    "        print(\"  \" * indent + \"{\")\n",
    "        for key, value in obj.items():\n",
    "            print(\"  \" * (indent + 1) + f'\"{key}\": ', end=\"\")\n",
    "            if isinstance(value, (dict, list)):\n",
    "                print_json_skeleton(value, indent + 1, max_depth, current_depth + 1)\n",
    "            else:\n",
    "                print(f\"{type(value).__name__}\")\n",
    "        print(\"  \" * indent + \"}\")\n",
    "    elif isinstance(obj, list):\n",
    "        print(\"  \" * indent + \"[\")\n",
    "        if len(obj) > 0:\n",
    "            print_json_skeleton(obj[0], indent + 1, max_depth, current_depth + 1)\n",
    "            if len(obj) > 1:\n",
    "                print(\"  \" * (indent + 1) + f\"... ({len(obj)} items)\")\n",
    "        print(\"  \" * indent + \"]\")\n",
    "    else:\n",
    "        print(f\"{type(obj).__name__}\")\n",
    "\n",
    "print_json_skeleton(results_list_with_family_properties[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d00e703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorchEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
