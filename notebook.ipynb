{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcd5222b",
   "metadata": {},
   "source": [
    "# GraphUniverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d85bb71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Function to load a pickle file\n",
    "def load_pickle_file(file_path):\n",
    "    \"\"\"\n",
    "    Load a pickle file and return its contents\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the pickle file\n",
    "    \n",
    "    Returns:\n",
    "        object: The loaded object from the pickle file\n",
    "    \"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        print(f\"Successfully loaded pickle file: {file_path}\")\n",
    "        print(f\"Data type: {type(data)}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading pickle file: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage:\n",
    "# Replace 'your_file.pkl' with the path to your pickle file\n",
    "# data = load_pickle_file('your_file.pkl')\n",
    "# print(data)\n",
    "\n",
    "\n",
    "# Additional utility functions for pickle files\n",
    "\n",
    "def inspect_pickle_contents(file_path, max_items=10):\n",
    "    \"\"\"\n",
    "    Inspect the contents of a pickle file without fully loading large objects\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): Path to the pickle file\n",
    "        max_items (int): Maximum number of items to display if data is iterable\n",
    "    \"\"\"\n",
    "    data = load_pickle_file(file_path)\n",
    "    if data is None:\n",
    "        return\n",
    "    \n",
    "    print(f\"\\n=== Pickle File Analysis ===\")\n",
    "    print(f\"File: {file_path}\")\n",
    "    print(f\"Type: {type(data)}\")\n",
    "    print(f\"Size in memory: {len(str(data))} characters (string representation)\")\n",
    "    \n",
    "    # Handle different data types\n",
    "    if hasattr(data, '__len__') and not isinstance(data, str):\n",
    "        print(f\"Length: {len(data)}\")\n",
    "    \n",
    "    if isinstance(data, dict):\n",
    "        print(f\"Dictionary keys: {list(data.keys())[:max_items]}\")\n",
    "        if len(data) > max_items:\n",
    "            print(f\"... and {len(data) - max_items} more keys\")\n",
    "    elif isinstance(data, (list, tuple)):\n",
    "        print(f\"First {min(max_items, len(data))} items:\")\n",
    "        for i, item in enumerate(data[:max_items]):\n",
    "            print(f\"  [{i}]: {type(item)} - {str(item)[:100]}\")\n",
    "        if len(data) > max_items:\n",
    "            print(f\"... and {len(data) - max_items} more items\")\n",
    "    else:\n",
    "        # For other types, just show a preview\n",
    "        data_str = str(data)\n",
    "        if len(data_str) > 200:\n",
    "            print(f\"Preview: {data_str[:200]}...\")\n",
    "        else:\n",
    "            print(f\"Content: {data_str}\")\n",
    "\n",
    "def list_pickle_files(directory=\".\"):\n",
    "    \"\"\"\n",
    "    List all pickle files in a directory\n",
    "    \n",
    "    Args:\n",
    "        directory (str): Directory to search for pickle files\n",
    "    \"\"\"\n",
    "    pickle_extensions = ['.pkl', '.pck', '.pickle']\n",
    "    pickle_files = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if any(file.endswith(ext) for ext in pickle_extensions):\n",
    "                pickle_files.append(os.path.join(root, file))\n",
    "    \n",
    "    if pickle_files:\n",
    "        print(f\"Found {len(pickle_files)} pickle files:\")\n",
    "        for file in pickle_files:\n",
    "            print(f\"  - {file}\")\n",
    "    else:\n",
    "        print(f\"No pickle files found in {directory}\")\n",
    "    \n",
    "    return pickle_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516f36cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gbg141/.conda/envs/tb/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for pickle files...\n",
      "Found 12 pickle files:\n",
      "  - /home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_50_to_100/10_communities_per_graph/pyg_graph_list_community_detection.pkl\n",
      "  - /home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_50_to_100/10_communities_per_graph/graph_universe.pkl\n",
      "  - /home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_50_to_100/5_to_10_communities_per_graph/pyg_graph_list_community_detection.pkl\n",
      "  - /home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_50_to_100/5_to_10_communities_per_graph/graph_universe.pkl\n",
      "  - /home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_50_to_100/2_to_5_communities_per_graph/pyg_graph_list_community_detection.pkl\n",
      "  - /home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_50_to_100/2_to_5_communities_per_graph/graph_universe.pkl\n",
      "  - /home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_20_to_40/10_communities_per_graph/pyg_graph_list_community_detection.pkl\n",
      "  - /home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_20_to_40/10_communities_per_graph/graph_universe.pkl\n",
      "  - /home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_20_to_40/5_to_10_communities_per_graph/pyg_graph_list_community_detection.pkl\n",
      "  - /home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_20_to_40/5_to_10_communities_per_graph/graph_universe.pkl\n",
      "  - /home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_20_to_40/2_to_5_communities_per_graph/pyg_graph_list_community_detection.pkl\n",
      "  - /home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_20_to_40/2_to_5_communities_per_graph/graph_universe.pkl\n",
      "Pickle file not found. Available files: ['/home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_50_to_100/10_communities_per_graph/pyg_graph_list_community_detection.pkl', '/home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_50_to_100/10_communities_per_graph/graph_universe.pkl', '/home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_50_to_100/5_to_10_communities_per_graph/pyg_graph_list_community_detection.pkl', '/home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_50_to_100/5_to_10_communities_per_graph/graph_universe.pkl', '/home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_50_to_100/2_to_5_communities_per_graph/pyg_graph_list_community_detection.pkl', '/home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_50_to_100/2_to_5_communities_per_graph/graph_universe.pkl', '/home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_20_to_40/10_communities_per_graph/pyg_graph_list_community_detection.pkl', '/home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_20_to_40/10_communities_per_graph/graph_universe.pkl', '/home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_20_to_40/5_to_10_communities_per_graph/pyg_graph_list_community_detection.pkl', '/home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_20_to_40/5_to_10_communities_per_graph/graph_universe.pkl', '/home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_20_to_40/2_to_5_communities_per_graph/pyg_graph_list_community_detection.pkl', '/home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/graph_size_20_to_40/2_to_5_communities_per_graph/graph_universe.pkl']\n"
     ]
    }
   ],
   "source": [
    "# Import the graph generation classes\n",
    "from graph_universe.model import GraphUniverse, GraphSample, GraphFamilyGenerator\n",
    "from utils.visualizations import (\n",
    "    plot_graph_communities, \n",
    "    plot_universe_degree_centers\n",
    ")\n",
    "\n",
    "# First, let's see what pickle files are available in the current directory and subdirectories\n",
    "print(\"Searching for pickle files...\")\n",
    "pickle_files = list_pickle_files(\"/home/gbg141/TopoBench\")\n",
    "\n",
    "# If you have a specific pickle file path, replace it here:\n",
    "your_pickle_file = \"/home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter/family_k10/2_to_5_communities_per_graph/pyg_graph_list_community_detection.pkl\"\n",
    "\n",
    "# Load and inspect the file\n",
    "if os.path.exists(your_pickle_file):\n",
    "    # Option 1: Just load the file\n",
    "    data = load_pickle_file(your_pickle_file)\n",
    "    \n",
    "    # Option 2: Load and inspect the contents\n",
    "    inspect_pickle_contents(your_pickle_file)\n",
    "else:\n",
    "    print(f\"Pickle file not found. Available files: {pickle_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da83c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "from torch_geometric.io import fs\n",
    "import pickle\n",
    "import os.path as osp\n",
    "from omegaconf import DictConfig\n",
    "\n",
    "parameters = {\n",
    "    \"data_domain\": \"graph\",\n",
    "    \"data_type\": \"GraphUniverse\",\n",
    "    \"data_name\": \"GraphUniverse\",\n",
    "    \"K\": 10,\n",
    "    \"graph_sizes\": [50,100],\n",
    "    \"per_graph_communities\": [2,5],\n",
    "    \"task\": \"community_detection\",\n",
    "    \"data_dir\": \"/data/gbg141/TB/datasets/graph/GraphUniverse\"\n",
    "}\n",
    "parameters = DictConfig(parameters)\n",
    "\n",
    "class GraphUniverseDataset(InMemoryDataset):\n",
    "    r\"\"\"Dataset class for GraphUniverse datasets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    root : str\n",
    "        Root directory where the dataset will be saved.\n",
    "    name : str\n",
    "        Name of the dataset.\n",
    "    parameters : DictConfig\n",
    "        Configuration parameters for the dataset.\n",
    "    **kwargs : dict\n",
    "        Additional keyword arguments.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        name: str,\n",
    "        parameters: DictConfig,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        self.parameters = parameters\n",
    "        self.family = f\"family_k{parameters.K}\"\n",
    "        self.graph_sizes = f\"graph_size_{parameters.graph_sizes[0]}_to_{parameters.graph_sizes[1]}\"\n",
    "        self.per_graph_communities = f\"{parameters.per_graph_communities[0]}_to_{parameters.per_graph_communities[1]}_communities_per_graph\" #if type(parameters.per_graph_communities)==list else f\"{parameters.graph_sizes}_communities_per_graph\"\n",
    "        self.task = f\"task_{parameters.task}\"\n",
    "        self.name = \"_\".join([self.family, self.graph_sizes, self.per_graph_communities, self.task])\n",
    "        PATH_TO_DATASETS = \"/home/gbg141/TopoBench/tutorials/first_graphuniverse_datasets_K_parameter\"\n",
    "        self.dataset_path = \"/\".join([PATH_TO_DATASETS, self.family, self.graph_sizes, self.per_graph_communities, f\"pyg_graph_list_{parameters.task}.pkl\"])\n",
    "        super().__init__(\n",
    "            root,\n",
    "        )\n",
    "        self.process()\n",
    "\n",
    "    @property\n",
    "    def raw_dir(self) -> str:\n",
    "        \"\"\"Return the path to the raw directory of the dataset.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Path to the raw directory.\n",
    "        \"\"\"\n",
    "        return osp.join(\n",
    "            self.root,\n",
    "            self.name,\n",
    "            \"raw\",\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def processed_dir(self) -> str:\n",
    "        \"\"\"Return the path to the processed directory of the dataset.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Path to the processed directory.\n",
    "        \"\"\"\n",
    "        self.processed_root = osp.join(\n",
    "            self.root,\n",
    "            self.name,\n",
    "        )\n",
    "        return osp.join(self.processed_root, \"processed\")\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> list[str]:\n",
    "        \"\"\"Return the raw file names for the dataset.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[str]\n",
    "            List of raw file names.\n",
    "        \"\"\"\n",
    "        return [f\"{self.dataset_path}\"]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        \"\"\"Return the processed file name for the dataset.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        str\n",
    "            Processed file name.\n",
    "        \"\"\"\n",
    "        return \"data.pt\"\n",
    "\n",
    "    def download(self) -> None:\n",
    "        r\"\"\"Download the dataset from a URL and saves it to the raw directory.\n",
    "\n",
    "        Raises:\n",
    "            FileNotFoundError: If the dataset URL is not found.\n",
    "        \"\"\"\n",
    "        # Nothing to download\n",
    "        pass\n",
    "\n",
    "\n",
    "    def process(self) -> None:\n",
    "        r\"\"\"Handle the data for the dataset.\n",
    "        \"\"\"\n",
    "\n",
    "        with open(self.dataset_path, 'rb') as f:\n",
    "            data_list = pickle.load(f)\n",
    "\n",
    "        self.data, self.slices = self.collate(data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b09cf3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "dataset = GraphUniverseDataset(parameters[\"data_dir\"], None, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7cf07468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[75825, 15], edge_index=[2, 450596], y=[75825])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset._data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0ad8dbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[51, 15], edge_index=[2, 170], y=[51])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7845fc0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
